{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "single-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "macro-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate, BatchNormalization, Dropout\n",
    "from keras.models import Model\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "precious-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12,8]\n",
    "plt.rc('font', size=20)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=24)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=24)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=20)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=15.5)    # legend fontsize\n",
    "plt.rc('figure', titlesize=50)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-dispatch",
   "metadata": {},
   "source": [
    "# NCF Grid Search Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sought-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info_all_df = pd.read_csv('models/model_info_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "three-upper",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model</th>\n",
       "      <th>test mse</th>\n",
       "      <th>test preds std</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning rate</th>\n",
       "      <th>n_nodes_per_layer</th>\n",
       "      <th>n_factors</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout_prob</th>\n",
       "      <th>patience</th>\n",
       "      <th>early stopping metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.877472</td>\n",
       "      <td>5.548574e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.886648</td>\n",
       "      <td>7.023544e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>25</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>0.888470</td>\n",
       "      <td>5.652527e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>0.891468</td>\n",
       "      <td>5.828209e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.902415</td>\n",
       "      <td>6.159833e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>0.905209</td>\n",
       "      <td>6.811764e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.911475</td>\n",
       "      <td>6.475879e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>25</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0.916098</td>\n",
       "      <td>6.232197e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.916653</td>\n",
       "      <td>5.753726e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>25</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>0.917084</td>\n",
       "      <td>7.627777e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0.917157</td>\n",
       "      <td>5.667948e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.919421</td>\n",
       "      <td>6.171350e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>25</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>0.921898</td>\n",
       "      <td>6.177047e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>25</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.924760</td>\n",
       "      <td>5.723780e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.927066</td>\n",
       "      <td>6.902538e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0.928927</td>\n",
       "      <td>6.995279e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>0.932384</td>\n",
       "      <td>5.926540e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.933122</td>\n",
       "      <td>6.311221e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0.933879</td>\n",
       "      <td>5.336142e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.934081</td>\n",
       "      <td>5.721201e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.938347</td>\n",
       "      <td>6.110622e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.940308</td>\n",
       "      <td>7.624888e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0.941317</td>\n",
       "      <td>5.417421e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.943484</td>\n",
       "      <td>4.970675e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>0.948172</td>\n",
       "      <td>7.389269e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>25</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0.948740</td>\n",
       "      <td>6.225435e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0.949946</td>\n",
       "      <td>5.673180e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>25</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0.952384</td>\n",
       "      <td>4.929947e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>4.695295e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>25</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0.955227</td>\n",
       "      <td>6.216265e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0.956591</td>\n",
       "      <td>5.476946e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0.956819</td>\n",
       "      <td>5.424585e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0.957209</td>\n",
       "      <td>5.882846e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0.960314</td>\n",
       "      <td>6.746171e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>25</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.963125</td>\n",
       "      <td>5.286373e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.963839</td>\n",
       "      <td>5.012519e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0.969456</td>\n",
       "      <td>6.258727e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>25</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.970778</td>\n",
       "      <td>5.901970e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>0.972987</td>\n",
       "      <td>5.761100e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973115</td>\n",
       "      <td>7.585462e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>0.978274</td>\n",
       "      <td>5.343440e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0.979853</td>\n",
       "      <td>4.914095e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>25</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.981411</td>\n",
       "      <td>5.788589e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>0.989098</td>\n",
       "      <td>5.653604e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.989277</td>\n",
       "      <td>4.518268e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.004528</td>\n",
       "      <td>4.958499e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1.021591</td>\n",
       "      <td>5.991637e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>1.023493</td>\n",
       "      <td>5.359974e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>1.025694</td>\n",
       "      <td>6.918979e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1.045184</td>\n",
       "      <td>5.060006e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>1.096202</td>\n",
       "      <td>4.138818e-01</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>1.254869</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>1.254871</td>\n",
       "      <td>4.768372e-07</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.254872</td>\n",
       "      <td>2.260892e-06</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1.255152</td>\n",
       "      <td>7.152557e-07</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>1.255259</td>\n",
       "      <td>4.768372e-07</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.255260</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1.255522</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>1.256698</td>\n",
       "      <td>7.152557e-07</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.257792</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]</td>\n",
       "      <td>25</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  model  test mse  test preds std  epochs  learning rate  \\\n",
       "22          22     22  0.877472    5.548574e-01     250         0.0010   \n",
       "5            5      5  0.886648    7.023544e-01     250         0.0100   \n",
       "41          41     41  0.888470    5.652527e-01     250         0.0100   \n",
       "49          49     49  0.891468    5.828209e-01     250         0.0100   \n",
       "11          11     11  0.902415    6.159833e-01     250         0.0001   \n",
       "48          48     48  0.905209    6.811764e-01     250         0.1000   \n",
       "6            6      6  0.911475    6.475879e-01     250         0.0010   \n",
       "29          29     29  0.916098    6.232197e-01     250         0.0100   \n",
       "7            7      7  0.916653    5.753726e-01     250         0.0001   \n",
       "57          57     57  0.917084    7.627777e-01     250         0.0100   \n",
       "31          31     31  0.917157    5.667948e-01     250         0.0001   \n",
       "25          25     25  0.919421    6.171350e-01     250         0.0100   \n",
       "45          45     45  0.921898    6.177047e-01     250         0.0100   \n",
       "52          52     52  0.924760    5.723780e-01     250         0.1000   \n",
       "10          10     10  0.927066    6.902538e-01     250         0.0010   \n",
       "37          37     37  0.928927    6.995279e-01     250         0.0100   \n",
       "53          53     53  0.932384    5.926540e-01     250         0.0100   \n",
       "50          50     50  0.933122    6.311221e-01     250         0.0010   \n",
       "42          42     42  0.933879    5.336142e-01     250         0.0010   \n",
       "15          15     15  0.934081    5.721201e-01     250         0.0001   \n",
       "17          17     17  0.938347    6.110622e-01     250         0.0100   \n",
       "8            8      8  0.940308    7.624888e-01     250         0.1000   \n",
       "39          39     39  0.941317    5.417421e-01     250         0.0001   \n",
       "19          19     19  0.943484    4.970675e-01     250         0.0001   \n",
       "44          44     44  0.948172    7.389269e-01     250         0.1000   \n",
       "21          21     21  0.948740    6.225435e-01     250         0.0100   \n",
       "27          27     27  0.949946    5.673180e-01     250         0.0001   \n",
       "43          43     43  0.952384    4.929947e-01     250         0.0001   \n",
       "47          47     47  0.953846    4.695295e-01     250         0.0001   \n",
       "38          38     38  0.955227    6.216265e-01     250         0.0010   \n",
       "54          54     54  0.956591    5.476946e-01     250         0.0010   \n",
       "34          34     34  0.956819    5.424585e-01     250         0.0010   \n",
       "59          59     59  0.957209    5.882846e-01     250         0.0001   \n",
       "26          26     26  0.960314    6.746171e-01     250         0.0010   \n",
       "18          18     18  0.963125    5.286373e-01     250         0.0010   \n",
       "2            2      2  0.963839    5.012519e-01     250         0.0010   \n",
       "24          24     24  0.969456    6.258727e-01     250         0.1000   \n",
       "14          14     14  0.970778    5.901970e-01     250         0.0010   \n",
       "58          58     58  0.972987    5.761100e-01     250         0.0010   \n",
       "0            0      0  0.973115    7.585462e-01     250         0.1000   \n",
       "35          35     35  0.978274    5.343440e-01     250         0.0001   \n",
       "46          46     46  0.979853    4.914095e-01     250         0.0010   \n",
       "13          13     13  0.981411    5.788589e-01     250         0.0100   \n",
       "51          51     51  0.989098    5.653604e-01     250         0.0001   \n",
       "3            3      3  0.989277    4.518268e-01     250         0.0001   \n",
       "16          16     16  1.004528    4.958499e-01     250         0.1000   \n",
       "40          40     40  1.021591    5.991637e-01     250         0.1000   \n",
       "36          36     36  1.023493    5.359974e-01     250         0.1000   \n",
       "32          32     32  1.025694    6.918979e-01     250         0.1000   \n",
       "30          30     30  1.045184    5.060006e-01     250         0.0010   \n",
       "33          33     33  1.096202    4.138818e-01     250         0.0100   \n",
       "55          55     55  1.254869    2.384186e-07     250         0.0001   \n",
       "23          23     23  1.254871    4.768372e-07     250         0.0001   \n",
       "1            1      1  1.254872    2.260892e-06     250         0.0100   \n",
       "20          20     20  1.255152    7.152557e-07     250         0.1000   \n",
       "28          28     28  1.255259    4.768372e-07     250         0.1000   \n",
       "9            9      9  1.255260    0.000000e+00     250         0.0100   \n",
       "12          12     12  1.255522    0.000000e+00     250         0.1000   \n",
       "56          56     56  1.256698    7.152557e-07     250         0.1000   \n",
       "4            4      4  1.257792    0.000000e+00     250         0.1000   \n",
       "\n",
       "                             n_nodes_per_layer  n_factors  batch_size  \\\n",
       "22        [512, 256, 128, 64, 32, 16, 8, 4, 2]          5         256   \n",
       "5   [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]         25         256   \n",
       "41             [256, 128, 64, 32, 16, 8, 4, 2]          5         256   \n",
       "49             [256, 128, 64, 32, 16, 8, 4, 2]         50         256   \n",
       "11  [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]         50         256   \n",
       "48             [256, 128, 64, 32, 16, 8, 4, 2]         50         256   \n",
       "6   [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]         25         256   \n",
       "29        [512, 256, 128, 64, 32, 16, 8, 4, 2]         50         256   \n",
       "7   [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]         25         256   \n",
       "57             [256, 128, 64, 32, 16, 8, 4, 2]        200         256   \n",
       "31        [512, 256, 128, 64, 32, 16, 8, 4, 2]         50         256   \n",
       "25        [512, 256, 128, 64, 32, 16, 8, 4, 2]         25         256   \n",
       "45             [256, 128, 64, 32, 16, 8, 4, 2]         25         256   \n",
       "52             [256, 128, 64, 32, 16, 8, 4, 2]        100         256   \n",
       "10  [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]         50         256   \n",
       "37        [512, 256, 128, 64, 32, 16, 8, 4, 2]        200         256   \n",
       "53             [256, 128, 64, 32, 16, 8, 4, 2]        100         256   \n",
       "50             [256, 128, 64, 32, 16, 8, 4, 2]         50         256   \n",
       "42             [256, 128, 64, 32, 16, 8, 4, 2]          5         256   \n",
       "15  [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]        100         256   \n",
       "17  [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]        200         256   \n",
       "8   [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]         50         256   \n",
       "39        [512, 256, 128, 64, 32, 16, 8, 4, 2]        200         256   \n",
       "19  [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]        200         256   \n",
       "44             [256, 128, 64, 32, 16, 8, 4, 2]         25         256   \n",
       "21        [512, 256, 128, 64, 32, 16, 8, 4, 2]          5         256   \n",
       "27        [512, 256, 128, 64, 32, 16, 8, 4, 2]         25         256   \n",
       "43             [256, 128, 64, 32, 16, 8, 4, 2]          5         256   \n",
       "47             [256, 128, 64, 32, 16, 8, 4, 2]         25         256   \n",
       "38        [512, 256, 128, 64, 32, 16, 8, 4, 2]        200         256   \n",
       "54             [256, 128, 64, 32, 16, 8, 4, 2]        100         256   \n",
       "34        [512, 256, 128, 64, 32, 16, 8, 4, 2]        100         256   \n",
       "59             [256, 128, 64, 32, 16, 8, 4, 2]        200         256   \n",
       "26        [512, 256, 128, 64, 32, 16, 8, 4, 2]         25         256   \n",
       "18  [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]        200         256   \n",
       "2   [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]          5         256   \n",
       "24        [512, 256, 128, 64, 32, 16, 8, 4, 2]         25         256   \n",
       "14  [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]        100         256   \n",
       "58             [256, 128, 64, 32, 16, 8, 4, 2]        200         256   \n",
       "0   [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]          5         256   \n",
       "35        [512, 256, 128, 64, 32, 16, 8, 4, 2]        100         256   \n",
       "46             [256, 128, 64, 32, 16, 8, 4, 2]         25         256   \n",
       "13  [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]        100         256   \n",
       "51             [256, 128, 64, 32, 16, 8, 4, 2]         50         256   \n",
       "3   [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]          5         256   \n",
       "16  [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]        200         256   \n",
       "40             [256, 128, 64, 32, 16, 8, 4, 2]          5         256   \n",
       "36        [512, 256, 128, 64, 32, 16, 8, 4, 2]        200         256   \n",
       "32        [512, 256, 128, 64, 32, 16, 8, 4, 2]        100         256   \n",
       "30        [512, 256, 128, 64, 32, 16, 8, 4, 2]         50         256   \n",
       "33        [512, 256, 128, 64, 32, 16, 8, 4, 2]        100         256   \n",
       "55             [256, 128, 64, 32, 16, 8, 4, 2]        100         256   \n",
       "23        [512, 256, 128, 64, 32, 16, 8, 4, 2]          5         256   \n",
       "1   [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]          5         256   \n",
       "20        [512, 256, 128, 64, 32, 16, 8, 4, 2]          5         256   \n",
       "28        [512, 256, 128, 64, 32, 16, 8, 4, 2]         50         256   \n",
       "9   [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]         50         256   \n",
       "12  [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]        100         256   \n",
       "56             [256, 128, 64, 32, 16, 8, 4, 2]        200         256   \n",
       "4   [1024, 512, 256, 128, 64, 32, 16, 8, 4, 2]         25         256   \n",
       "\n",
       "    dropout_prob  patience early stopping metric  \n",
       "22           0.2         5              val_loss  \n",
       "5            0.2         5              val_loss  \n",
       "41           0.2         5              val_loss  \n",
       "49           0.2         5              val_loss  \n",
       "11           0.2         5              val_loss  \n",
       "48           0.2         5              val_loss  \n",
       "6            0.2         5              val_loss  \n",
       "29           0.2         5              val_loss  \n",
       "7            0.2         5              val_loss  \n",
       "57           0.2         5              val_loss  \n",
       "31           0.2         5              val_loss  \n",
       "25           0.2         5              val_loss  \n",
       "45           0.2         5              val_loss  \n",
       "52           0.2         5              val_loss  \n",
       "10           0.2         5              val_loss  \n",
       "37           0.2         5              val_loss  \n",
       "53           0.2         5              val_loss  \n",
       "50           0.2         5              val_loss  \n",
       "42           0.2         5              val_loss  \n",
       "15           0.2         5              val_loss  \n",
       "17           0.2         5              val_loss  \n",
       "8            0.2         5              val_loss  \n",
       "39           0.2         5              val_loss  \n",
       "19           0.2         5              val_loss  \n",
       "44           0.2         5              val_loss  \n",
       "21           0.2         5              val_loss  \n",
       "27           0.2         5              val_loss  \n",
       "43           0.2         5              val_loss  \n",
       "47           0.2         5              val_loss  \n",
       "38           0.2         5              val_loss  \n",
       "54           0.2         5              val_loss  \n",
       "34           0.2         5              val_loss  \n",
       "59           0.2         5              val_loss  \n",
       "26           0.2         5              val_loss  \n",
       "18           0.2         5              val_loss  \n",
       "2            0.2         5              val_loss  \n",
       "24           0.2         5              val_loss  \n",
       "14           0.2         5              val_loss  \n",
       "58           0.2         5              val_loss  \n",
       "0            0.2         5              val_loss  \n",
       "35           0.2         5              val_loss  \n",
       "46           0.2         5              val_loss  \n",
       "13           0.2         5              val_loss  \n",
       "51           0.2         5              val_loss  \n",
       "3            0.2         5              val_loss  \n",
       "16           0.2         5              val_loss  \n",
       "40           0.2         5              val_loss  \n",
       "36           0.2         5              val_loss  \n",
       "32           0.2         5              val_loss  \n",
       "30           0.2         5              val_loss  \n",
       "33           0.2         5              val_loss  \n",
       "55           0.2         5              val_loss  \n",
       "23           0.2         5              val_loss  \n",
       "1            0.2         5              val_loss  \n",
       "20           0.2         5              val_loss  \n",
       "28           0.2         5              val_loss  \n",
       "9            0.2         5              val_loss  \n",
       "12           0.2         5              val_loss  \n",
       "56           0.2         5              val_loss  \n",
       "4            0.2         5              val_loss  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info_all_df.sort_values('test mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-grocery",
   "metadata": {
    "tags": []
   },
   "source": [
    "The model with the lowest test MSE is Model 22."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-engineering",
   "metadata": {},
   "source": [
    "# TFIDF Grid Search Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chubby-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_full_tfidf_df = pd.read_csv('../final_result_full_tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "rural-pierre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>sim_method</th>\n",
       "      <th>algo</th>\n",
       "      <th>sim_threshold</th>\n",
       "      <th>neighbors</th>\n",
       "      <th>sig_weight</th>\n",
       "      <th>weighting_factor</th>\n",
       "      <th>coverage</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>new_get_TFIDF_recommendations</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99743</td>\n",
       "      <td>1.048402</td>\n",
       "      <td>1.023915</td>\n",
       "      <td>0.816841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>new_get_TFIDF_recommendations</td>\n",
       "      <td>0.306194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99715</td>\n",
       "      <td>1.054174</td>\n",
       "      <td>1.026730</td>\n",
       "      <td>0.818359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>new_get_TFIDF_recommendations</td>\n",
       "      <td>0.576448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98334</td>\n",
       "      <td>1.104257</td>\n",
       "      <td>1.050836</td>\n",
       "      <td>0.829047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>new_get_TFIDF_recommendations</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83227</td>\n",
       "      <td>1.267398</td>\n",
       "      <td>1.125788</td>\n",
       "      <td>0.863466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_name sim_method                           algo  sim_threshold  \\\n",
       "0      ml-100k      TFIDF  new_get_TFIDF_recommendations       0.000000   \n",
       "1      ml-100k      TFIDF  new_get_TFIDF_recommendations       0.306194   \n",
       "2      ml-100k      TFIDF  new_get_TFIDF_recommendations       0.576448   \n",
       "3      ml-100k      TFIDF  new_get_TFIDF_recommendations       0.846703   \n",
       "\n",
       "   neighbors  sig_weight  weighting_factor  coverage       mse      rmse  \\\n",
       "0          0           0                 0   0.99743  1.048402  1.023915   \n",
       "1          0           0                 0   0.99715  1.054174  1.026730   \n",
       "2          0           0                 0   0.98334  1.104257  1.050836   \n",
       "3          0           0                 0   0.83227  1.267398  1.125788   \n",
       "\n",
       "        mae  \n",
       "0  0.816841  \n",
       "1  0.818359  \n",
       "2  0.829047  \n",
       "3  0.863466  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_full_tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "asian-ceiling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>sim_method</th>\n",
       "      <th>algo</th>\n",
       "      <th>sim_threshold</th>\n",
       "      <th>neighbors</th>\n",
       "      <th>sig_weight</th>\n",
       "      <th>weighting_factor</th>\n",
       "      <th>coverage</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>new_get_TFIDF_recommendations</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99743</td>\n",
       "      <td>1.048402</td>\n",
       "      <td>1.023915</td>\n",
       "      <td>0.816841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>new_get_TFIDF_recommendations</td>\n",
       "      <td>0.306194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99715</td>\n",
       "      <td>1.054174</td>\n",
       "      <td>1.026730</td>\n",
       "      <td>0.818359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>new_get_TFIDF_recommendations</td>\n",
       "      <td>0.576448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98334</td>\n",
       "      <td>1.104257</td>\n",
       "      <td>1.050836</td>\n",
       "      <td>0.829047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>new_get_TFIDF_recommendations</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83227</td>\n",
       "      <td>1.267398</td>\n",
       "      <td>1.125788</td>\n",
       "      <td>0.863466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_name sim_method                           algo  sim_threshold  \\\n",
       "0      ml-100k      TFIDF  new_get_TFIDF_recommendations       0.000000   \n",
       "1      ml-100k      TFIDF  new_get_TFIDF_recommendations       0.306194   \n",
       "2      ml-100k      TFIDF  new_get_TFIDF_recommendations       0.576448   \n",
       "3      ml-100k      TFIDF  new_get_TFIDF_recommendations       0.846703   \n",
       "\n",
       "   neighbors  sig_weight  weighting_factor  coverage       mse      rmse  \\\n",
       "0          0           0                 0   0.99743  1.048402  1.023915   \n",
       "1          0           0                 0   0.99715  1.054174  1.026730   \n",
       "2          0           0                 0   0.98334  1.104257  1.050836   \n",
       "3          0           0                 0   0.83227  1.267398  1.125788   \n",
       "\n",
       "        mae  \n",
       "0  0.816841  \n",
       "1  0.818359  \n",
       "2  0.829047  \n",
       "3  0.863466  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_full_tfidf_df.sort_values('mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-quantum",
   "metadata": {},
   "source": [
    "The TFIDF model with the lowest MSE/best coverage has a sim_threshold of 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-finance",
   "metadata": {},
   "source": [
    "# Hybrid Grid Search Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "blessed-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_full_hybrid_df = pd.read_csv('../final_result_full_hybrid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "southern-winner",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>sim_method</th>\n",
       "      <th>algo</th>\n",
       "      <th>sim_threshold</th>\n",
       "      <th>neighbors</th>\n",
       "      <th>sig_weight</th>\n",
       "      <th>weighting_factor</th>\n",
       "      <th>coverage</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99955</td>\n",
       "      <td>1.001539</td>\n",
       "      <td>1.000769</td>\n",
       "      <td>0.797949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.99955</td>\n",
       "      <td>1.009658</td>\n",
       "      <td>1.004818</td>\n",
       "      <td>0.801366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.99955</td>\n",
       "      <td>1.019228</td>\n",
       "      <td>1.009568</td>\n",
       "      <td>0.805351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99930</td>\n",
       "      <td>1.029657</td>\n",
       "      <td>1.014720</td>\n",
       "      <td>0.809199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.99955</td>\n",
       "      <td>1.031056</td>\n",
       "      <td>1.015409</td>\n",
       "      <td>0.810160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.99930</td>\n",
       "      <td>1.033208</td>\n",
       "      <td>1.016469</td>\n",
       "      <td>0.810670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.99930</td>\n",
       "      <td>1.037195</td>\n",
       "      <td>1.018428</td>\n",
       "      <td>0.812297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.306194</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99756</td>\n",
       "      <td>1.038395</td>\n",
       "      <td>1.019017</td>\n",
       "      <td>0.811929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.99930</td>\n",
       "      <td>1.041837</td>\n",
       "      <td>1.020704</td>\n",
       "      <td>0.814153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.306194</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.99724</td>\n",
       "      <td>1.052063</td>\n",
       "      <td>1.025701</td>\n",
       "      <td>0.817443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.306194</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.99715</td>\n",
       "      <td>1.054166</td>\n",
       "      <td>1.026726</td>\n",
       "      <td>0.818356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.306194</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.99715</td>\n",
       "      <td>1.054174</td>\n",
       "      <td>1.026730</td>\n",
       "      <td>0.818359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.306194</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.99715</td>\n",
       "      <td>1.054174</td>\n",
       "      <td>1.026730</td>\n",
       "      <td>0.818359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.306194</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.99715</td>\n",
       "      <td>1.054174</td>\n",
       "      <td>1.026730</td>\n",
       "      <td>0.818359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.306194</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99715</td>\n",
       "      <td>1.054174</td>\n",
       "      <td>1.026730</td>\n",
       "      <td>0.818359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.306194</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.99715</td>\n",
       "      <td>1.054174</td>\n",
       "      <td>1.026730</td>\n",
       "      <td>0.818359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.576448</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98334</td>\n",
       "      <td>1.104217</td>\n",
       "      <td>1.050817</td>\n",
       "      <td>0.829031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.576448</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98334</td>\n",
       "      <td>1.104257</td>\n",
       "      <td>1.050836</td>\n",
       "      <td>0.829047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.576448</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.98334</td>\n",
       "      <td>1.104257</td>\n",
       "      <td>1.050836</td>\n",
       "      <td>0.829047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.576448</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.98334</td>\n",
       "      <td>1.104257</td>\n",
       "      <td>1.050836</td>\n",
       "      <td>0.829047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.576448</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.98334</td>\n",
       "      <td>1.104257</td>\n",
       "      <td>1.050836</td>\n",
       "      <td>0.829047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.576448</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.98334</td>\n",
       "      <td>1.104257</td>\n",
       "      <td>1.050836</td>\n",
       "      <td>0.829047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.576448</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.98334</td>\n",
       "      <td>1.104257</td>\n",
       "      <td>1.050836</td>\n",
       "      <td>0.829047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.576448</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.98334</td>\n",
       "      <td>1.104257</td>\n",
       "      <td>1.050836</td>\n",
       "      <td>0.829047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83227</td>\n",
       "      <td>1.267398</td>\n",
       "      <td>1.125788</td>\n",
       "      <td>0.863466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.83227</td>\n",
       "      <td>1.267398</td>\n",
       "      <td>1.125788</td>\n",
       "      <td>0.863466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.83227</td>\n",
       "      <td>1.267398</td>\n",
       "      <td>1.125788</td>\n",
       "      <td>0.863466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.83227</td>\n",
       "      <td>1.267398</td>\n",
       "      <td>1.125788</td>\n",
       "      <td>0.863466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.83227</td>\n",
       "      <td>1.267398</td>\n",
       "      <td>1.125788</td>\n",
       "      <td>0.863466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_distance at 0x7fdf515cf700&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.83227</td>\n",
       "      <td>1.267398</td>\n",
       "      <td>1.125788</td>\n",
       "      <td>0.863466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.83227</td>\n",
       "      <td>1.267398</td>\n",
       "      <td>1.125788</td>\n",
       "      <td>0.863466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ml-100k</td>\n",
       "      <td>&lt;function sim_pearson at 0x7fdf515cf790&gt;</td>\n",
       "      <td>new_get_hybrid_recommendations</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83227</td>\n",
       "      <td>1.267398</td>\n",
       "      <td>1.125788</td>\n",
       "      <td>0.863466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_name                                 sim_method  \\\n",
       "7       ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "5       ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "3       ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "6       ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "1       ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "4       ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "2       ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "15      ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "0       ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "13      ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "11      ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "9       ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "10      ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "12      ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "14      ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "8       ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "23      ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "22      ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "21      ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "20      ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "18      ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "17      ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "16      ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "19      ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "30      ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "24      ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "25      ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "26      ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "27      ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "28      ml-100k  <function sim_distance at 0x7fdf515cf700>   \n",
       "29      ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "31      ml-100k   <function sim_pearson at 0x7fdf515cf790>   \n",
       "\n",
       "                              algo  sim_threshold  neighbors  sig_weight  \\\n",
       "7   new_get_hybrid_recommendations       0.000000        100         100   \n",
       "5   new_get_hybrid_recommendations       0.000000        100         100   \n",
       "3   new_get_hybrid_recommendations       0.000000        100         100   \n",
       "6   new_get_hybrid_recommendations       0.000000        100         100   \n",
       "1   new_get_hybrid_recommendations       0.000000        100         100   \n",
       "4   new_get_hybrid_recommendations       0.000000        100         100   \n",
       "2   new_get_hybrid_recommendations       0.000000        100         100   \n",
       "15  new_get_hybrid_recommendations       0.306194        100         100   \n",
       "0   new_get_hybrid_recommendations       0.000000        100         100   \n",
       "13  new_get_hybrid_recommendations       0.306194        100         100   \n",
       "11  new_get_hybrid_recommendations       0.306194        100         100   \n",
       "9   new_get_hybrid_recommendations       0.306194        100         100   \n",
       "10  new_get_hybrid_recommendations       0.306194        100         100   \n",
       "12  new_get_hybrid_recommendations       0.306194        100         100   \n",
       "14  new_get_hybrid_recommendations       0.306194        100         100   \n",
       "8   new_get_hybrid_recommendations       0.306194        100         100   \n",
       "23  new_get_hybrid_recommendations       0.576448        100         100   \n",
       "22  new_get_hybrid_recommendations       0.576448        100         100   \n",
       "21  new_get_hybrid_recommendations       0.576448        100         100   \n",
       "20  new_get_hybrid_recommendations       0.576448        100         100   \n",
       "18  new_get_hybrid_recommendations       0.576448        100         100   \n",
       "17  new_get_hybrid_recommendations       0.576448        100         100   \n",
       "16  new_get_hybrid_recommendations       0.576448        100         100   \n",
       "19  new_get_hybrid_recommendations       0.576448        100         100   \n",
       "30  new_get_hybrid_recommendations       0.846703        100         100   \n",
       "24  new_get_hybrid_recommendations       0.846703        100         100   \n",
       "25  new_get_hybrid_recommendations       0.846703        100         100   \n",
       "26  new_get_hybrid_recommendations       0.846703        100         100   \n",
       "27  new_get_hybrid_recommendations       0.846703        100         100   \n",
       "28  new_get_hybrid_recommendations       0.846703        100         100   \n",
       "29  new_get_hybrid_recommendations       0.846703        100         100   \n",
       "31  new_get_hybrid_recommendations       0.846703        100         100   \n",
       "\n",
       "    weighting_factor  coverage       mse      rmse       mae  \n",
       "7               1.00   0.99955  1.001539  1.000769  0.797949  \n",
       "5               0.75   0.99955  1.009658  1.004818  0.801366  \n",
       "3               0.50   0.99955  1.019228  1.009568  0.805351  \n",
       "6               1.00   0.99930  1.029657  1.014720  0.809199  \n",
       "1               0.25   0.99955  1.031056  1.015409  0.810160  \n",
       "4               0.75   0.99930  1.033208  1.016469  0.810670  \n",
       "2               0.50   0.99930  1.037195  1.018428  0.812297  \n",
       "15              1.00   0.99756  1.038395  1.019017  0.811929  \n",
       "0               0.25   0.99930  1.041837  1.020704  0.814153  \n",
       "13              0.75   0.99724  1.052063  1.025701  0.817443  \n",
       "11              0.50   0.99715  1.054166  1.026726  0.818356  \n",
       "9               0.25   0.99715  1.054174  1.026730  0.818359  \n",
       "10              0.50   0.99715  1.054174  1.026730  0.818359  \n",
       "12              0.75   0.99715  1.054174  1.026730  0.818359  \n",
       "14              1.00   0.99715  1.054174  1.026730  0.818359  \n",
       "8               0.25   0.99715  1.054174  1.026730  0.818359  \n",
       "23              1.00   0.98334  1.104217  1.050817  0.829031  \n",
       "22              1.00   0.98334  1.104257  1.050836  0.829047  \n",
       "21              0.75   0.98334  1.104257  1.050836  0.829047  \n",
       "20              0.75   0.98334  1.104257  1.050836  0.829047  \n",
       "18              0.50   0.98334  1.104257  1.050836  0.829047  \n",
       "17              0.25   0.98334  1.104257  1.050836  0.829047  \n",
       "16              0.25   0.98334  1.104257  1.050836  0.829047  \n",
       "19              0.50   0.98334  1.104257  1.050836  0.829047  \n",
       "30              1.00   0.83227  1.267398  1.125788  0.863466  \n",
       "24              0.25   0.83227  1.267398  1.125788  0.863466  \n",
       "25              0.25   0.83227  1.267398  1.125788  0.863466  \n",
       "26              0.50   0.83227  1.267398  1.125788  0.863466  \n",
       "27              0.50   0.83227  1.267398  1.125788  0.863466  \n",
       "28              0.75   0.83227  1.267398  1.125788  0.863466  \n",
       "29              0.75   0.83227  1.267398  1.125788  0.863466  \n",
       "31              1.00   0.83227  1.267398  1.125788  0.863466  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_full_hybrid_df.sort_values('mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-kansas",
   "metadata": {},
   "source": [
    "The Hybrid-Pearson model with the lowest mse has a sim_threshold of 0, 100 neighbors, a similarity significance weighting cutoff of 100, and a weighting factor of 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-transcript",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "attractive-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_user_distance_mse = 0.761348 # From midterm analysis.ipynb file, with threshold of 0.1, sig_weight of 25\n",
    "best_user_pearson_mse = 0.769243 # From midterm analysis.ipynb file, with threshold of 0.3, sig_weight of 25\n",
    "best_item_distance_mse = 0.652500 # From midterm analysis.ipynb file, with threshold of 0.0, sig_weight of 100\n",
    "best_item_pearson_mse = 0.659491 # From midterm analysis.ipynb file, with threshold of 0.0, sig_weight of 100\n",
    "best_mf_sgd_mse = 0.91 # from MF homework PDF\n",
    "best_mf_als_mse = 0.99 # from MF homework PDF\n",
    "best_tfidf_mse = float(final_result_full_tfidf_df.iloc[[0]]['mse'])\n",
    "best_hybrid_pearson_mse = float(final_result_full_hybrid_df.iloc[[7]]['mse'])\n",
    "best_hybrid_distance_mse = float(final_result_full_hybrid_df.iloc[[6]]['mse'])\n",
    "best_ncf_mse = float(model_info_all_df[model_info_all_df['model'] == 22]['test mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "loose-strip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "height_list = [best_user_distance_mse,\n",
    "               best_user_pearson_mse,\n",
    "               best_item_distance_mse,\n",
    "               best_item_pearson_mse,\n",
    "               best_mf_sgd_mse, \n",
    "               best_mf_als_mse, \n",
    "               best_tfidf_mse, \n",
    "               best_hybrid_pearson_mse, \n",
    "               best_hybrid_distance_mse, \n",
    "               best_ncf_mse]\n",
    "\n",
    "model_labels_list = ['user-d', 'user-p', 'item-d', 'item-p', 'mf-sgd', 'mf-als', 'tfidf', 'hyb-p', 'hyb-d', 'ncf']\n",
    "plt.bar(x = model_labels_list, height = height_list)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('models')\n",
    "plt.ylabel('mse')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.savefig('../figures/model_comparison_bar.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-helen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
